{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport numpy_api_stats.numpy_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy_api_stats as ns\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_results_fn = 'full_results_4_10_2019.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns.plot_results(pd.read_csv(accumulated_results_fn),savefig=True,filename='results.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_results_by_project = 'percent_by_project.csv'\n",
    "det_percentages = pd.read_csv(accumulated_results_by_project).set_index('index')\n",
    "f1 = ns.plot_bar_repo(det_percentages)\n",
    "f1.savefig('bar_repo.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_percentages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_CRED_DIR']=os.path.join(os.environ['HOME'],'creds')\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']=os.path.join(os.environ['GOOGLE_CRED_DIR'],'apt-footing-235018-aeb185ac9e31.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate bigQuery public github dataset contents using bqhelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.cloud import bigquery\n",
    "github_repos = ns.BigQueryHelper(active_project= \"bigquery-public-data\", \n",
    "                                       dataset_name = \"github_repos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_repos.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_results = ns.BigQueryHelper(active_project= \"apt-footing-235018\", \n",
    "                                       dataset_name = \"NumpyAPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_results.list_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_results = api_results.head(\"latest_numpy_agg_repo_name\",num_rows=10)\n",
    "agg_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe for plot  This pulls aggregate table from BigQuery, formats for plot, and saves to .csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create dataframe for plot  This pu\n",
    "_list_agg = api_results.query_to_pandas_safe('''\n",
    "SELECT * FROM `apt-footing-235018.NumpyAPI.latest_numpy_agg_repo_from_list`\n",
    "''')\n",
    "\n",
    "list_agg = _list_agg.set_index('repo_name')\n",
    "\n",
    "list_agg = list_agg.drop(['f0_','numpy_module_numpy_count'],axis=1)\n",
    "\n",
    "scipy_api = list_agg.loc['teoliphant/scipy']\n",
    "Nscipy = scipy_api.sum()\n",
    "\n",
    "cupy_api = list_agg.loc['cupy/cupy']\n",
    "Ncupy = cupy_api.sum()\n",
    "\n",
    "dask_api = list_agg.loc['mikegraham/dask']\n",
    "Ndask = dask_api.sum()\n",
    "\n",
    "pandas_api = list_agg.loc['pandas-dev/pandas']\n",
    "Npandas = pandas_api.sum()\n",
    "\n",
    "det_percentages = pd.DataFrame([cupy_api/Ncupy, pandas_api/Npandas, scipy_api/Nscipy, dask_api/Ndask])\n",
    "\n",
    "det_percentages = det_percentages[ det_percentages.mean().sort_values(ascending=False).index ]\n",
    "\n",
    "det_percentages.reset_index().to_csv('percent_by_project.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following is some analysis of API member functions and experiments with query generation Construct API datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "api = [(x, type(np.__getattribute__(x))) for x in dir(np) if not x.startswith('__')]\n",
    "things = set([ x[1].__name__ for x in api])\n",
    "names = set([ x[0] for x in api])\n",
    "df_api = pd.DataFrame(api,columns=['name','type'])\n",
    "\n",
    "array_type = df_api[df_api.name=='array']\n",
    "things_of_array_type = df_api[df_api.type == array_type.type.values[0]]\n",
    "#things_of_array_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api[df_api.name=='linalg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleSheet = pd.read_csv('NumPy API - Sheet2.csv')\n",
    "names_from_sheet = GoogleSheet['NumPy API']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_names = set(names_from_sheet)-set(['Functions','bench',np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = set(names)-set(names_from_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_from_sheet = df_api.set_index('name').loc[valid_names]\n",
    "df_valid_from_sheet = df_valid_from_sheet.reset_index()\n",
    "df_valid_from_sheet['type'] = df_valid_from_sheet.type.apply(lambda x: x.__name__)\n",
    "df_valid_from_sheet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many of each type in the api are represented in the Google Sheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_from_sheet[['type','name']].groupby(['type']).count().sort_values('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Of which, the following have not been implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid_from_sheet.set_index('type').loc[['CClass','NoneType','PytestTester','RClass','bool','IndexExpression','_typedict','str','nd_grid','_Feature','dict']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Constructed for API functions..  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting just a few for demonstration, Query price is independent of # of regex though, so it is better to actually run\n",
    "# with all at once.\n",
    "\n",
    "funs = ns.select(api,'function')\n",
    "mods = ns.select(api,'module')\n",
    "ints = ns.select(api,'int')\n",
    "floats = ns.select(api,'float')\n",
    "ufuncs = ns.select(api,'ufunc')\n",
    "api_list = funs[:2]+mods[:2]+ints[:2]+floats[:2]+ufuncs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all to build full query running \n",
    "#api_list=ns.build_api_list(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(api_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy_api_stats as ns\n",
    "apq = ns.API_QUERY_FACTORY(api_list=api_list)\n",
    "#apq = ns.API_QUERY_FACTORY()\n",
    "print(apq.query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AFter copying and pasting the above query into BigQuery and saving as sample_results... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####Unfortunately this doesn't work https://github.com/dask/dask/issues/3121 so we manually export results."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import dask.dataframe as dd\n",
    "df = dd.read_csv('gs://numpy_api_study/  np_results_*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pull data from bigQuery.  This is a one row table with a a few hundred columns so is relatively inexpensive to pull, but we'll download a local copy and work from that anyway to reduce wear on our ISP's routers."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r = api_results.query_to_pandas_safe('SELECT * FROM `apt-footing-235018.NumpyAPI.results4`')\n",
    "ns.plot_results(r,savefig=True,filename='results.png',dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### references\n",
    "- [Florin Badita](https://medium.com/google-cloud/naming-conventions-in-python-import-statements-a-bigquery-adventure-using-the-github-db-dump-d900159ab680)\n",
    "- [Felipe Hoffa](https://medium.com/google-cloud/github-on-bigquery-analyze-all-the-code-b3576fd2b150)\n",
    "- [Walker Harrison](https://dev.to/walker/using-googles-bigquery-to-better-understand-the-python-ecosystem)\n",
    "- [Robert Kozikowski](https://kozikow.com/2016/06/05/more-advanced-github-code-search/)\n",
    "- [Poonam Ligade](https://www.kaggle.com/poonaml/analyzing-3-million-github-repos-using-bigquery)\n",
    "- [Sohier Dane](https://github.com/SohierDane/BigQuery_Helper/blob/master/bq_helper.py)\n",
    "- [Google BigQuery](https://cloud.google.com/bigquery/docs/reference/legacy-sql)\n",
    "- [Cloud API](https://googleapis.github.io/google-cloud-python/latest/bigquery/usage/queries.html)\n",
    "- [Numpy API](https://docs.google.com/spreadsheets/d/10Tf_FK4FHaS0rpgBIuK43RHTPR601RD4p39gZQRZ2Yg/edit#gid=74265489)\n",
    "- [Numpy Book](https://docs.scipy.org/doc/_static/numpybook.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "One possivility would be to use User defined functions [ Big Query UDF ](https://cloudplatform.googleblog.com/2015/08/Google-BigQuery-adds-UDF-support-for-deeper-cloud-analytics.html) in bigQuery for better python parsing, and thus bias reduction in api detection\n",
    "Apparently there is a tool to facilitate UDF development [ UDF Test Tool](http://storage.googleapis.com/bigquery-udf-test-tool/testtool.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach may be to search in popular repos for numpy dependencies using direct AST walking.  The following approach uses the inspection module to retrieve source code for a scipy module, and search the AST for numpy calls.  Information on AST nodes can be found at [ Green Tree Snakes ](https://greentreesnakes.readthedocs.io/en/latest/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/Users/mpeaton/SCIPY/build/lib.macosx-10.7-x86_64-3.7/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "from scipy.linalg import basic as basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlist= inspect.getmembers(basic)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AST node walk based api search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import ast\n",
    "import numpy_api_stats as ns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from scipy.linalg import basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ast.parse(inspect.getsource(basic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atleast_2d',\n",
       " 'atleast_1d',\n",
       " 'np.concatenate',\n",
       " 'atleast_1d',\n",
       " 'atleast_1d',\n",
       " 'np.abs',\n",
       " 'np.any',\n",
       " 'np.identity',\n",
       " 'np.sum',\n",
       " 'np.transpose',\n",
       " 'np.dot',\n",
       " 'atleast_2d',\n",
       " 'np.ones_like',\n",
       " 'np.arange',\n",
       " 'np.empty_like',\n",
       " 'np.arange',\n",
       " 'np.asfortranarray',\n",
       " 'np.iscomplexobj',\n",
       " 'np.array',\n",
       " 'np.zeros',\n",
       " 'np.iscomplexobj',\n",
       " 'np.iscomplexobj',\n",
       " 'np.asarray',\n",
       " 'np.asarray',\n",
       " 'np.asarray',\n",
       " 'np.asarray',\n",
       " 'np.column_stack',\n",
       " 'np.rollaxis',\n",
       " 'np.rollaxis',\n",
       " 'np.rollaxis',\n",
       " 'np.zeros',\n",
       " 'np.asarray',\n",
       " 'np.conjugate',\n",
       " 'np.equal',\n",
       " 'np.ascontiguousarray',\n",
       " 'atleast_1d',\n",
       " 'np.ones_like',\n",
       " 'np.iscomplexobj',\n",
       " 'np.iscomplexobj',\n",
       " 'np.empty',\n",
       " 'np.empty',\n",
       " 'np.zeros',\n",
       " 'np.zeros',\n",
       " 'np.finfo',\n",
       " 'np.zeros',\n",
       " 'np.dot',\n",
       " 'np.max',\n",
       " 'np.conjugate',\n",
       " 'np.diag',\n",
       " 'np.finfo',\n",
       " 'np.common_type',\n",
       " 'np.sum',\n",
       " 'np.array',\n",
       " 'np.finfo',\n",
       " 'np.max',\n",
       " 'np.finfo',\n",
       " 'np.ascontiguousarray',\n",
       " 'np.abs']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns.get_npcalls(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uarray)",
   "language": "python",
   "name": "uarray"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
